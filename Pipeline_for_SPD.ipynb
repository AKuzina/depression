{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm_notebook\n",
    "import time\n",
    "import os\n",
    "%pylab inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import RepeatedStratifiedKFold, StratifiedKFold, StratifiedShuffleSplit, cross_val_score, cross_val_predict, GridSearchCV\n",
    "from sklearn.feature_selection import SelectFromModel, VarianceThreshold, SelectKBest, f_classif, chi2\n",
    "from sklearn.ensemble import RandomForestClassifier, ExtraTreesClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_curve, roc_auc_score, confusion_matrix\n",
    "from sklearn.preprocessing import Imputer, StandardScaler, LabelEncoder\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.manifold import LocallyLinearEmbedding\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.externals import joblib\n",
    "\n",
    "from scipy import stats\n",
    "import scipy.io\n",
    "import pyriemann as pr\n",
    "import networkx as nx\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SPD_pipeline():\n",
    "    def __init__(self, threshold, lam):\n",
    "        self.threshold = threshold\n",
    "        self.lam = lam\n",
    "        \n",
    "    def get_spd_dataset(self, data):\n",
    "        res = map(self.create_spd, data)\n",
    "        return np.stack(res, axis=0)\n",
    "        \n",
    "    def create_spd(self, X):\n",
    "        N = X.shape[0]\n",
    "        binary_matrix = (abs(X) > self.threshold).astype(int)\n",
    "#         binary_matrix = X\n",
    "        G = nx.from_numpy_array(binary_matrix)\n",
    "        X_lp = nx.laplacian_matrix(G)\n",
    "        return X_lp.toarray() + self.lam*np.eye(N)\n",
    "        \n",
    "    def get_svc_grid(self, cv, scoring, random_state=None, n_jobs=1,\n",
    "                     svc_kernel_l=None, svc_c_l=None, svc_gamma_l=None, metric=None, update = None):\n",
    "\n",
    "        \"\"\"\n",
    "        define GridSearchCV object for kernel SVC pipeline, for given parameters\n",
    "        \"\"\"\n",
    "        clf = pr.classification.TSclassifier(clf=SVC(random_state=random_state, probability=True))\n",
    "\n",
    "        param_grid = { }\n",
    "        \n",
    "        if svc_kernel_l is not None:\n",
    "            param_grid['clf__kernel'] = svc_kernel_l\n",
    "        if svc_c_l is not None:\n",
    "            param_grid['clf__C'] = svc_c_l\n",
    "        if svc_gamma_l is not None:\n",
    "            param_grid['clf__gamma'] = svc_gamma_l\n",
    "        if metric is not None:\n",
    "            param_grid['metric'] = metric\n",
    "        if update is not None:\n",
    "            param_grid['tsupdate'] = update\n",
    "        \n",
    "        return GridSearchCV(estimator = clf, param_grid=param_grid, scoring=scoring, cv=cv, n_jobs=n_jobs, verbose = 1)\n",
    "    \n",
    "    def get_lr_grid(self, cv, scoring, random_state=None, n_jobs=1, lr_c_l=None, metric=None, update=None):\n",
    "        \n",
    "        \"\"\"\n",
    "        define GridSearchCV object for LR on tangency plane pipeline\n",
    "        \"\"\"\n",
    "\n",
    "        clf = pr.classification.TSclassifier(clf=LogisticRegression(random_state=random_state))\n",
    "        param_grid = { }\n",
    "        \n",
    "        if lr_c_l is not None:\n",
    "            param_grid['clf__C'] = lr_c_l\n",
    "        if metric is not None:\n",
    "            param_grid['metric'] = metric\n",
    "        if update is not None:\n",
    "            param_grid['tsupdate'] = update\n",
    "        \n",
    "        return GridSearchCV(estimator=clf, param_grid=param_grid, scoring=scoring, cv=cv, n_jobs=n_jobs, verbose = 1)\n",
    "    \n",
    "    def get_knn_grid(self, cv, scoring, random_state=None, n_jobs=1, knn_n_neighbors_l=None, metric=None):\n",
    "        \"\"\"\n",
    "        define GridSearchCV object for kNN on the manifold pipeline\n",
    "        \"\"\"\n",
    "        clf = pr.classification.KNearestNeighbor(n_jobs=n_jobs)\n",
    "        param_grid = { }\n",
    "        \n",
    "        if knn_n_neighbors_l is not None:\n",
    "            param_grid['n_neighbors'] = knn_n_neighbors_l\n",
    "        if metric is not None:\n",
    "            param_grid['metric'] = metric\n",
    "            \n",
    "        return  GridSearchCV(estimator=clf, param_grid=param_grid, scoring=scoring, cv=cv, n_jobs=n_jobs, verbose = 1)\n",
    "\n",
    "            \n",
    "    def get_mdm_grid(self, cv, scoring, random_state=None, n_jobs=1, metric=None):\n",
    "        \"\"\"\n",
    "        define GridSearchCV object for min distance to mean on the manifold pipeline\n",
    "        \"\"\"\n",
    "\n",
    "        clf = pr.classification.MDM(n_jobs=n_jobs)\n",
    "        \n",
    "        param_grid = { }\n",
    "        \n",
    "        if metric is not None:\n",
    "            param_grid['metric'] = metric\n",
    "            \n",
    "        return  GridSearchCV(estimator=clf, param_grid=param_grid, scoring=scoring, cv=cv, n_jobs=n_jobs, verbose = 1)\n",
    "    \n",
    "    \n",
    "    def train_grid_cv(self, data, y, n_splits, n_repeats, \n",
    "                      scoring, pos_label=None, random_state=None, \n",
    "                      n_jobs=1, save_plot_to=None, save_models_to=None):\n",
    "                     \n",
    "        \"\"\"\n",
    "        train all the grids, passed to it\n",
    "        returns: best model and all the trained grids\n",
    "        \"\"\"\n",
    "        X = self.get_spd_dataset(data)\n",
    "\n",
    "#         X = data \n",
    "        cv = RepeatedStratifiedKFold(n_splits=n_splits, n_repeats=n_repeats, random_state=random_state)\n",
    "        print(\"Target distribution: \")\n",
    "        print(y.value_counts(), \"\\n\")\n",
    "        if pos_label is None:\n",
    "            y_enc = pd.Series(LabelEncoder().fit_transform(y), index=y.index)\n",
    "        else:\n",
    "            y_enc = pd.Series(y == pos_label, dtype=int)\n",
    "\n",
    "        #### SVC ####\n",
    "        if os.path.isfile(save_models_to + '_svc.pkl'):\n",
    "            print('loading fitted SVC...\\n')\n",
    "            grid_cv_svc = self.load_model(save_models_to + '_svc.pkl')\n",
    "        else:\n",
    "            print(\"Training SVC...\")\n",
    "            grid_cv_svc = self.get_svc_grid(cv, scoring, random_state=random_state, n_jobs=n_jobs,\n",
    "                                       svc_kernel_l=[\"rbf\", \"linear\"],\n",
    "                                       svc_c_l=[10 ** i for i in range(-4, 4, 2)],\n",
    "                                       svc_gamma_l=[10 ** i for i in range(-4, 2, 2)],\n",
    "                                       metric = ['riemann', 'logeuclid', 'euclid'])\n",
    "#             grid_cv_svc = self.get_svc_grid(cv, scoring, random_state=random_state, n_jobs=n_jobs,\n",
    "#                                        svc_kernel_l=[\"linear\"],\n",
    "#                                        svc_c_l=[10 ** i for i in range(-1, 1, 2)],\n",
    "#                                        svc_gamma_l=[10 ** i for i in range(-1, 1, 2)],\n",
    "#                                        metric = ['riemann'])\n",
    "            start_time = time.time()\n",
    "            grid_cv_svc.fit(X, y_enc)\n",
    "            print(\"(training took {}s)\\n\".format(time.time() - start_time))\n",
    "            \n",
    "        if save_models_to is not None:\n",
    "            self.save_model(grid_cv_svc, save_models_to + '_svc.pkl')\n",
    "            \n",
    "        #### LR ####    \n",
    "        if os.path.isfile(save_models_to + '_lr.pkl'):\n",
    "            print('loading fitted LR...\\n')\n",
    "            grid_cv_lr = self.load_model(save_models_to + '_lr.pkl')\n",
    "        else:\n",
    "            print(\"Training LR...\")\n",
    "            grid_cv_lr = self.get_lr_grid(cv, scoring, random_state=random_state, n_jobs=n_jobs,\n",
    "                                     lr_c_l=[10 ** i for i in range(-4, 2, 2)],\n",
    "                                     metric = ['riemann', 'logeuclid', 'euclid'])\n",
    "#             grid_cv_lr = self.get_lr_grid(cv, scoring, random_state=random_state, n_jobs=n_jobs,\n",
    "#                                      lr_c_l=[10 ** i for i in range(-1, 1, 2)],\n",
    "#                                      metric = ['riemann'])\n",
    "            start_time = time.time()\n",
    "            grid_cv_lr.fit(X, y_enc)\n",
    "            print(\"(training took {}s)\\n\".format(time.time() - start_time))\n",
    "            \n",
    "        if save_models_to is not None:\n",
    "            self.save_model(grid_cv_lr, save_models_to + '_lr.pkl')\n",
    "            \n",
    "        #### KNN ####    \n",
    "        if os.path.isfile(save_models_to + '_knn.pkl'):\n",
    "            print('loading fitted KNN...\\n')\n",
    "            grid_cv_knn = self.load_model(save_models_to + '_knn.pkl')\n",
    "        else:\n",
    "            print(\"Training KNN...\")\n",
    "            class_size_tr = min(y.value_counts())\n",
    "            grid_cv_knn = self.get_knn_grid(cv, scoring, random_state=random_state, n_jobs=n_jobs,\n",
    "                                       knn_n_neighbors_l=[i for i in range(5, class_size_tr - 1, 5)],\n",
    "                                       metric = ['riemann', 'logeuclid', 'euclid'])\n",
    "#             grid_cv_knn = self.get_knn_grid(cv, scoring, random_state=random_state, n_jobs=n_jobs,\n",
    "#                                        knn_n_neighbors_l=[10],\n",
    "#                                        metric = ['riemann'])        \n",
    "            start_time = time.time()\n",
    "            grid_cv_knn.fit(X, np.array(y_enc))\n",
    "            print(\"(training took {}s)\\n\".format(time.time() - start_time))\n",
    "            \n",
    "        if save_models_to is not None:\n",
    "            self.save_model(grid_cv_knn, save_models_to + '_knn.pkl')\n",
    "            \n",
    "            \n",
    "        #### MDM ####    \n",
    "        if os.path.isfile(save_models_to + '_mdm.pkl'):\n",
    "            print('loading fitted MDM...\\n')\n",
    "            grid_cv_mdm = self.load_model(save_models_to + '_mdm.pkl')\n",
    "        else:\n",
    "            print(\"Training MDM...\")\n",
    "            grid_cv_mdm = self.get_mdm_grid(cv, scoring, random_state=random_state, n_jobs=n_jobs,\n",
    "                                       metric = ['riemann', 'logeuclid', 'euclid'])\n",
    "#             grid_cv_mdm = self.get_mdm_grid(cv, scoring, random_state=random_state, n_jobs=n_jobs,\n",
    "#                                        metric = ['riemann'])\n",
    "            start_time = time.time()\n",
    "            grid_cv_mdm.fit(X, y_enc)\n",
    "            print(\"(training took {}s)\\n\".format(time.time() - start_time))\n",
    "\n",
    "        if save_models_to is not None:\n",
    "            self.save_model(grid_cv_mdm, save_models_to + '_mdm.pkl')\n",
    "            \n",
    "        \n",
    "        print(\"Scoring:\", scoring)\n",
    "        self.print_results({\n",
    "            \"SVC\" : grid_cv_svc,\n",
    "            \"LR\" : grid_cv_lr,\n",
    "            \"KNN\" : grid_cv_knn,\n",
    "            \"MDM\" : grid_cv_mdm\n",
    "                      }, save_plot_to=save_plot_to)\n",
    "\n",
    "        best_model = max([grid_cv_svc, grid_cv_lr, grid_cv_mdm, grid_cv_knn], key=lambda x: x.best_score_).best_estimator_\n",
    "\n",
    "        return best_model, grid_cv_svc, grid_cv_lr, grid_cv_mdm, grid_cv_knn\n",
    "    \n",
    "    def print_results(self, clf_grid_dict, save_plot_to=None):\n",
    "        \"\"\"\n",
    "        Draw beautiful table with results\n",
    "        \"\"\"\n",
    "        results = {\n",
    "                \"classifier\" : [], \n",
    "                \"best parameters\" : [],\n",
    "                \"mean\" : [],\n",
    "                \"std\" : []\n",
    "               }\n",
    "\n",
    "        for clf, grid in clf_grid_dict.items():\n",
    "            results[\"classifier\"].append(clf)\n",
    "            results[\"best parameters\"].append(\", \".join(\n",
    "                [param + \" = \" + str(best_value) for param, best_value in grid.best_params_.items()]))\n",
    "#                 results[\"best dim. reduction method\"].append(grid.best_params_['dim_reduction'])\n",
    "            idx = grid.best_index_\n",
    "            results[\"mean\"].append(grid.cv_results_['mean_test_score'][idx])\n",
    "            results[\"std\"].append(grid.cv_results_['std_test_score'][idx])\n",
    "\n",
    "        results = pd.DataFrame(results, columns=[\"classifier\", \"best parameters\", \"mean\", \"std\"])\n",
    "        display(results.set_index(\"classifier\"))\n",
    "\n",
    "        # draw graph\n",
    "        width = 0.9\n",
    "        for i in results.index:\n",
    "            plt.bar(i, results.loc[i, \"mean\"], width, yerr=results.loc[i, \"std\"], label=results.loc[i, \"classifier\"])\n",
    "        plt.xticks(range(results.shape[0]), results.loc[:, \"classifier\"])\n",
    "        plt.axis(ymin=0.0, ymax=1.0)\n",
    "        if save_plot_to is not None:\n",
    "            plt.savefig(save_plot_to)\n",
    "        plt.show()\n",
    "\n",
    "        print(\"Best model: \")\n",
    "        clf = results.loc[results[\"mean\"].argmax(), \"classifier\"]\n",
    "        print(clf)\n",
    "        print(\"\\n\".join(\n",
    "                [param + \" = \" + str(best_value) for param, best_value in clf_grid_dict[clf].best_params_.items()]))\n",
    "    #     print(\"mean =\", results[\"mean\"].max())\n",
    "    #     print(\"std =\", results.loc[results[\"mean\"].argmax(), \"std\"])\n",
    "    n_objects = 100\n",
    "\n",
    "    def repeated_cross_val_predict_proba(self, estimator, data, y, cv, pos_label=None, file=None):\n",
    "        X = self.get_spd_dataset(data)\n",
    "#         X = data\n",
    "        n_objects = X.shape[0]\n",
    "        \n",
    "        if pos_label is None:\n",
    "            y_enc = pd.Series(LabelEncoder().fit_transform(y), index=y.index)\n",
    "        else:\n",
    "            y_enc = pd.Series(y == pos_label, dtype=int)\n",
    "        predictions = [[] for i in range(n_objects)]\n",
    "        for idx_tr, idx_te in tqdm_notebook(cv.split(X, y_enc)):\n",
    "            estimator.fit(X[idx_tr,:,:], y_enc.iloc[idx_tr])\n",
    "            pred_te = np.array(estimator.predict_proba(X[idx_te,:,:]), dtype=float)\n",
    "            for i, idx in enumerate(idx_te):\n",
    "                predictions[idx].append(pred_te[i, 1])\n",
    "\n",
    "        predictions = pd.DataFrame(predictions)\n",
    "        if file is not None:\n",
    "            predictions.to_csv(file)\n",
    "\n",
    "        return predictions\n",
    "    \n",
    "    def plot_roc_curve(self, y, probas, pos_label, idx, average_repeats=False):\n",
    "        if average_repeats:\n",
    "            y_true = pd.Series(y == pos_label, dtype=int)\n",
    "#             y_score = probas[idx].mean(axis=1)\n",
    "            y_score = probas.mean(axis=1)\n",
    "        else:\n",
    "            n_repeats = probas.shape[1]\n",
    "            y_true = pd.Series(np.tile(y == pos_label, (n_repeats)), dtype=int)\n",
    "#             y_score = probas[idx].values.T.reshape(-1, 1)\n",
    "            y_score = probas.values.T.reshape(-1, 1)\n",
    "        fpr, tpr, t = roc_curve(y_true=y_true, y_score=y_score)\n",
    "        plt.figure(figsize=(12, 8))\n",
    "        plt.plot(fpr, tpr)\n",
    "        plt.xlabel(\"False Positive rate\", fontsize=14)\n",
    "        plt.ylabel(\"True Positive rate\", fontsize=14)\n",
    "        plt.show()\n",
    "        print(\"auc =\", roc_auc_score(y_true, y_score))\n",
    "        return fpr, tpr, t\n",
    "    \n",
    "    def get_fpr_fnr(self, fpr, tpr, fix_fpr_l=[0.1, 0.15, 0.2, 0.3]):\n",
    "        fnr_l = []\n",
    "        for fix_fpr in fix_fpr_l:\n",
    "            fnr_l.append(1 - tpr[fpr <= fix_fpr][-1])\n",
    "        fpr_fnr_table = pd.DataFrame(np.column_stack((fix_fpr_l, fnr_l)), columns=[\"False Positive rate (fixed)\", \"False Negative rate\"])\n",
    "        display(fpr_fnr_table)\n",
    "        return fpr_fnr_table\n",
    "    \n",
    "    def save_model(self, model, file):\n",
    "        joblib.dump(model, file)\n",
    "    \n",
    "    def load_model(self, file):\n",
    "        model = joblib.load(file)\n",
    "        return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
